{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c848f42-855c-4bcb-8a0f-7f697c1fd872",
   "metadata": {},
   "source": [
    "# WaDE Water Right Ex: Anlytics on Utah Domestic Water Rights\n",
    "#### By Adel Abdallah and Ryan James - Western States Water Council\n",
    "- Date Update: 11/20/2023\n",
    "- WaDE API documentation: https://api.westernstateswater.org/\n",
    "- Example API return for Water Right data: https://wade-api.azure-api.net/v1/SiteAllocationAmounts?BeneficialUseCV=Agriculture%20Irrigation&StartIndex=1&key=beba8a9dd8724fabb3b16d2a415e9aab\n",
    "\n",
    "Notes:\n",
    "- Our API only returns 1000 records at a time. We use a loop & append to dataframe approach here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c516e3b-feaf-4972-95d3-67d78dd08e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libararies\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "import openpyxl\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "print (\"Libararies have been imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbaabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting work directory\n",
    "cwd = os.getcwd()\n",
    "Output = cwd\n",
    "print(\"current directory = \"+Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6302a",
   "metadata": {},
   "source": [
    "## Retrieve Data using WaDE 2.0 SiteAllocationAmounts API.\n",
    "- performing a loop with StartIndex = 0, then do iterations of 1000 rows.\n",
    "- Default return is a 1000 rows per API call.  Can change with RecordCount element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f846cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dataframes to store each dictionary section of the API return.\n",
    "Organizations = pd.DataFrame()\n",
    "WaterSources = pd.DataFrame()\n",
    "VariableSpecifics = pd.DataFrame()\n",
    "Methods = pd.DataFrame()\n",
    "BeneficialUses = pd.DataFrame()\n",
    "WaterAllocations = pd.DataFrame()\n",
    "Sites = pd.DataFrame()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6bc33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-set base elements of API call for easy construction.\n",
    "# Save as strings.\n",
    "# uat connection\n",
    "\n",
    "# base API URL.\n",
    "base_url_API = \"https://wade-api.azure-api.net/v1/SiteAllocationAmounts?\"\n",
    "\n",
    "# set a benefical use pararemter as \"Agriculture Irrigation\" (%20 = \" \", blank splace)\n",
    "benUseParam = \"BeneficialUseCV=Domestic\"\n",
    "\n",
    "# limit search to state of interest, use abbreviation.\n",
    "stateParam = \"State=UT\"\n",
    "\n",
    "# security API Key.\n",
    "keyParam = \"key=beba8a9dd8724fabb3b16d2a415e9aab\"\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fb204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# loop over the API calls through pages (index) one-at-a-time. \n",
    "\n",
    "startIndex = 0  # will do bounds of 1000\n",
    "loopsToRun = 9 # number of loops we want to run\n",
    "\n",
    "\n",
    "# The loop\n",
    "loopCounter = 0  # counter of the number of loops\n",
    "while loopCounter < loopsToRun:\n",
    "    print(f'Loop #: ', loopCounter)\n",
    "\n",
    "    startIndexParam = \"StartIndex=\" + str(startIndex)\n",
    "    print (startIndexParam)\n",
    "    \n",
    "    # combine the API parameters together\n",
    "    callString = base_url_API + benUseParam + \"&\" + stateParam + \"&\" + startIndexParam + \"&\" + keyParam\n",
    "    print (callString)\n",
    "    \n",
    "    # Call the API, check if API has a response\n",
    "    # The get\n",
    "    try:\n",
    "        response_dict = requests.get(callString).json()\n",
    "        \n",
    "        # Indexing and list slicing to append to individual tables.\n",
    "        # Organizations Data       \n",
    "        o_json_data = response_dict['Organizations'][0]\n",
    "        o_tempDF = pd.json_normalize(o_json_data)\n",
    "        o_tempDF = pd.DataFrame(o_tempDF, columns=['OrganizationName',\n",
    "                                                        'OrganizationPurview',\n",
    "                                                        'OrganizationWebsite',\n",
    "                                                        'OrganizationState',\n",
    "                                                        'OrganizationContactEmail',\n",
    "                                                        'OrganizationPhoneNumber',\n",
    "                                                        'OrganizationContactName',\n",
    "                                                        'OrganizationContactEmail'], index=[0])\n",
    "        Organizations = pd.concat([Organizations, o_tempDF])\n",
    "\n",
    "        # WaterSource Data\n",
    "        ws_json_data = response_dict['Organizations'][0]['WaterSources']\n",
    "        ws_tempDF = pd.json_normalize(ws_json_data)\n",
    "        WaterSources = pd.concat([WaterSources, ws_tempDF])\n",
    "        \n",
    "        # VariableSpecifics Data\n",
    "        v_json_data = response_dict['Organizations'][0]['VariableSpecifics']\n",
    "        v_tempDF = pd.json_normalize(v_json_data)\n",
    "        VariableSpecifics = pd.concat([VariableSpecifics, v_tempDF])\n",
    "         \n",
    "        # Methods Data\n",
    "        m_json_data = response_dict['Organizations'][0]['Methods']\n",
    "        m_tempDF = pd.json_normalize(m_json_data)\n",
    "        Methods = pd.concat([Methods, m_tempDF])\n",
    "        \n",
    "        # BeneficialUses Data\n",
    "        bu_json_data = response_dict['Organizations'][0]['BeneficialUses']\n",
    "        bu_tempDF = pd.json_normalize(bu_json_data)\n",
    "        BeneficialUses = pd.concat([BeneficialUses, bu_tempDF])\n",
    "        \n",
    "        # WaterAllocations Data\n",
    "        wa_json_data = response_dict['Organizations'][0]['WaterAllocations']\n",
    "        wa_tempDF = pd.json_normalize(wa_json_data)\n",
    "        wa_tempDF['StartIndex'] = str(startIndex) #tracking StartIndex used\n",
    "        WaterAllocations = pd.concat([WaterAllocations, wa_tempDF])\n",
    "        \n",
    "        # Sites Data\n",
    "        s_json_data = response_dict['Organizations'][0]['Sites']\n",
    "        s_tempDF = pd.json_normalize(s_json_data)\n",
    "        Sites = pd.concat([Sites, s_tempDF])\n",
    "        \n",
    "    except:\n",
    "        print(\"StartIndex_param has no data\")\n",
    "          \n",
    "            \n",
    "    startIndex = startIndex + 1000\n",
    "    loopCounter = loopCounter + 1\n",
    "    \n",
    "    print(\"------------\")\n",
    "\n",
    "    \n",
    "# Remove duplicate based on unique UUID values from WaterSources, Variables, Methods, Beneficialuses, & Sites\n",
    "WaterSources = WaterSources.drop_duplicates().sort_values(by=['WaterSourceUUID']).reset_index(drop=True)\n",
    "VariableSpecifics = VariableSpecifics.drop_duplicates().reset_index(drop=True)\n",
    "Methods = Methods.drop_duplicates().sort_values(by=['MethodUUID']).reset_index(drop=True)\n",
    "BeneficialUses = BeneficialUses.drop_duplicates().sort_values(by=['Term']).reset_index(drop=True)\n",
    "Sites = Sites.drop_duplicates(subset=['SiteUUID']).sort_values(by=['SiteUUID']).reset_index(drop=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40b2ce",
   "metadata": {},
   "source": [
    "## Retrieve related POUs & PODS site info from sites dataframe, create new dataframe\n",
    "- Creating easy to ready table for related POD sites per POU site from *RelatedPODSites* and *RelatedPOUSites* fields.\n",
    "- Create temp POU table, create temp POD table, then concatenate into single output table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new POU specific dataframe, populate with items from Sites dataframe\n",
    "RelatedSitesPOU = pd.DataFrame()\n",
    "RelatedSitesPOU['SourceSiteUUID'] = Sites['SiteUUID']\n",
    "RelatedSitesPOU['SourcePODorPOU'] = Sites['PODorPOUSite']\n",
    "RelatedSitesPOU['RelatedPODSites'] = Sites['RelatedPODSites']\n",
    "RelatedSitesPOU = RelatedSitesPOU[RelatedSitesPOU['SourcePODorPOU'] == 'POU'].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    # explode the entries in the RelatedPODSites column, reset index.\n",
    "    RelatedSitesPOU = RelatedSitesPOU.assign(RelatedPODSites=RelatedSitesPOU['RelatedPODSites']).explode('RelatedPODSites').reset_index(drop=True)\n",
    "\n",
    "    # fetch column RelatedPODSites as a Series, then return dataframe where the column labels are the keys of the dictionaries.\n",
    "    RelatedSitesPOU = pd.concat([RelatedSitesPOU, RelatedSitesPOU[\"RelatedPODSites\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # rename columns\n",
    "    RelatedSitesPOU = RelatedSitesPOU.rename(columns={\"SiteUUID\": \"RelatedSiteUUID\"})\n",
    "\n",
    "    # drop index & RelatedPODSites columns from dataframe (no longer needed).\n",
    "    RelatedSitesPOU = RelatedSitesPOU.drop(columns=[\"RelatedPODSites\", 0])\n",
    "    \n",
    "except:\n",
    "    print(\"No POU sites for the returend SiteVariableAmounts records.\")\n",
    "    RelatedSitesPOU = pd.DataFrame()\n",
    "    RelatedSitesPOU = RelatedSitesPOU.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "\n",
    "# drop null rows\n",
    "RelatedSitesPOU = RelatedSitesPOU.dropna()\n",
    "\n",
    "print(len(RelatedSitesPOU))\n",
    "RelatedSitesPOU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new POD specific dataframe, populate with items from Sites dataframe\n",
    "RelatedSitesPOD = pd.DataFrame()\n",
    "RelatedSitesPOD['SourceSiteUUID'] = Sites['SiteUUID']\n",
    "RelatedSitesPOD['SourcePODorPOU'] = Sites['PODorPOUSite']\n",
    "RelatedSitesPOD['RelatedPOUSites'] = Sites['RelatedPOUSites']\n",
    "RelatedSitesPOD = RelatedSitesPOD[RelatedSitesPOD['SourcePODorPOU'] == 'POD'].reset_index(drop=True)\n",
    "\n",
    "try: \n",
    "    # explode the entries in the RelatedPOUSites column, reset index.\n",
    "    RelatedSitesPOD = RelatedSitesPOD.assign(RelatedPOUSites=RelatedSitesPOD['RelatedPOUSites']).explode('RelatedPOUSites').reset_index(drop=True)\n",
    "\n",
    "    # fetch column RelatedPOUSites as a Series, then return dataframe where the column labels are the keys of the dictionaries.\n",
    "    RelatedSitesPOD = pd.concat([RelatedSitesPOD, RelatedSitesPOD[\"RelatedPOUSites\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # rename columns\n",
    "    RelatedSitesPOD = RelatedSitesPOD.rename(columns={\"SiteUUID\": \"RelatedSiteUUID\"})\n",
    "\n",
    "    # drop index & RelatedPOUSites columns from dataframe (no longer needed).\n",
    "    RelatedSitesPOD = RelatedSitesPOD.drop(columns=[\"RelatedPOUSites\", 0])\n",
    "    \n",
    "except:\n",
    "    print(\"No POD sites for the returend SiteVariableAmounts records.\")\n",
    "    RelatedSitesPOD = pd.DataFrame()\n",
    "    RelatedSitesPOD = RelatedSitesPOD.append(pd.Series(), ignore_index=True)\n",
    "    \n",
    "\n",
    "# drop null rows\n",
    "RelatedSitesPOD = RelatedSitesPOD.dropna()\n",
    "\n",
    "print(len(RelatedSitesPOD))\n",
    "RelatedSitesPOD.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate POU with POD data\n",
    "try:\n",
    "    frames = [RelatedSitesPOU, RelatedSitesPOD]\n",
    "    RelatedSites = pd.concat(frames).reset_index(drop=True)\n",
    "    RelatedSites = RelatedSites.sort_values(by=['SourcePODorPOU', 'SourceSiteUUID', 'RelatedSiteUUID', 'StartDate', 'EndDate'])\n",
    "    print(len(RelatedSites))\n",
    "    RelatedSites.head(1)\n",
    "except:\n",
    "    print(\"No POD to POU relations in the data.\")\n",
    "    RelatedSites = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a68d36",
   "metadata": {},
   "source": [
    "## Export results\n",
    "- Create a Pandas Excel writer, save each dataframe to a separate sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('results/WaDE_API_Ex_Results.xlsx') as writer:\n",
    "    Organizations.to_excel(writer, sheet_name='Organizations')\n",
    "    WaterSources.to_excel(writer, sheet_name='WaterSources')\n",
    "    VariableSpecifics.to_excel(writer, sheet_name='VariableSpecifics')\n",
    "    Methods.to_excel(writer, sheet_name='Methods')\n",
    "    BeneficialUses.to_excel(writer, sheet_name='BeneficialUses')\n",
    "    WaterAllocations.to_excel(writer, sheet_name='WaterAllocations')\n",
    "    Sites.to_excel(writer, sheet_name='Sites')\n",
    "    RelatedSites.to_excel(writer, sheet_name='RelatedSites')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549188f",
   "metadata": {},
   "source": [
    "# Analytics and Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries / Modules\n",
    "\n",
    "# ---- working with data ----\n",
    "import os  # native operating system interaction\n",
    "import numpy as np  # mathematical array manipulation\n",
    "import pandas as pd  # data structure and data analysis\n",
    "import geopandas as gpd  # geo-data structure and data analysis\n",
    "\n",
    "# ---- visualization ----\n",
    "import geoplot as gplt  # for plotting maps and geo-data\n",
    "import geoplot.crs as gcrs  #used to pull in webdata related to maps and geo-data\n",
    "import missingno as msno # creates a matrix chart to show missing values\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go  # for subplot creation\n",
    "from plotly.subplots import make_subplots  # for subplot creation\n",
    "import matplotlib.pyplot as mplt  # use with gplt to save fig to pdf\n",
    "\n",
    "# ---- cleanup ----\n",
    "import re # string regular expression manipulation\n",
    "from datetime import datetime # date and time manipulation\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # suppress scientific notation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929bd4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- merge watersource.csv to sites.csv ----\n",
    "\n",
    "# explode site.csv on WaterSourceUUIDs\n",
    "dfstemp = Sites.copy()\n",
    "dfstemp = dfstemp.explode('WaterSourceUUIDs').reset_index(drop=True) # split WaterSourceUUIDs \n",
    "\n",
    "# merge\n",
    "dfstemp_ws = pd.merge(dfstemp, WaterSources[['WaterSourceUUID', 'WaterSourceTypeCV']], left_on='WaterSourceUUIDs', right_on='WaterSourceUUID', how='left')\n",
    "\n",
    "# groupby site-watersource.csv via SiteUUID\n",
    "dfstemp_ws = dfstemp_ws.groupby('SiteUUID').agg(lambda x: ','.join([str(elem) for elem in (list(set(x))) if elem != \"\"])).replace(np.nan, \"\").reset_index()\n",
    "\n",
    "print(len(dfstemp_ws))\n",
    "dfstemp_ws.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52586f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaterAllocations dataframe\n",
    "dfaa = WaterAllocations.copy()\n",
    "dfaa['BeneficialUses'] = [','.join(map(str, l)) for l in dfaa['BeneficialUses']] # convert from list to comma separated string\n",
    "dfaa['SitesUUIDs'] = [','.join(map(str, l)) for l in dfaa['SitesUUIDs']] # convert from list to comma separated string\n",
    "dfaa['AllocationPriorityDate'] = pd.to_datetime(dfaa['AllocationPriorityDate'], errors = 'coerce') # format to date value\n",
    "dfaa['AllocationPriorityDate'] = pd.to_datetime(dfaa[\"AllocationPriorityDate\"].dt.strftime('%m/%d/%Y')) # format data value to YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7018f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram: Num of POD sites vs POU sites ----\n",
    "print(dfstemp_ws.PODorPOUSite.value_counts())\n",
    "\n",
    "fig = px.histogram(dfstemp_ws, x=\"PODorPOUSite\")\n",
    "fig.update_layout(hovermode=False,\n",
    "                  bargap=0.2,\n",
    "                  title=\"Histogram of PODorPOUSite Entries in sites.csv\",\n",
    "                  xaxis_title=\"PODorPOUSite Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/PODorPOUSite.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05585bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram: Num of sites via WatersourceTypeCV ----\n",
    "print(dfstemp_ws.WaterSourceTypeCV.value_counts())\n",
    "\n",
    "fig = px.histogram(dfstemp_ws, x=\"WaterSourceTypeCV\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of WaterSourceTypeCV Entries in sites.csv\",\n",
    "                  xaxis_title=\"WaterSourceTypeCV Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/WaterSourceTypeCV.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a56a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram: Distribution of PrimaryBeneficialUseCategory WaDE Values ----\n",
    "print(dfaa.BeneficialUses.value_counts())\n",
    "\n",
    "fig = px.histogram(dfaa, x=\"BeneficialUses\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of WaDE BeneficialUses Entries in waterallocations.csv\",\n",
    "                  xaxis_title=\"BeneficialUses Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/BeneficialUses.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d74d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- AllocationPriorityDate #1: histogram distribution of WaDE values \n",
    "print(dfaa.AllocationPriorityDate.value_counts())\n",
    "\n",
    "dfaatemp = dfaa.copy()\n",
    "dfaatemp = dfaatemp[(dfaatemp['ExemptOfVolumeFlowPriority'] < 1)].reset_index(drop=True)\n",
    "fig = px.histogram(dfaatemp, x=\"AllocationPriorityDate\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of AllocationPriorityDate Entries in waterallocations.csv\",\n",
    "                  xaxis_title=\"AllocationPriorityDate Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/AllocationPriorityDate1.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- AllocationPriorityDate #2: cumulative distribution of WaDE values \n",
    "print(dfaa.AllocationPriorityDate.value_counts())\n",
    "\n",
    "dfaatemp = dfaa.copy()\n",
    "dfaatemp = dfaatemp[(dfaatemp['ExemptOfVolumeFlowPriority'] < 1)].reset_index(drop=True)\n",
    "fig = px.ecdf(dfaatemp, x=\"AllocationPriorityDate\", ecdfnorm=None)\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Cumulative Distribution of AllocationPriorityDate Entries in waterallocations.csv\",\n",
    "                  xaxis_title=\"AllocationPriorityDate Value\",\n",
    "                  xaxis=dict(tickformat=\"%Y-%M\"),\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "\n",
    "fig.show()\n",
    "fig.write_image('figures/AllocationPriorityDate2.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1959e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- AllocationLegalStatusCodeCV: histogram distribution of WaDE values ----\n",
    "print(dfaa.AllocationLegalStatusCodeCV.value_counts())\n",
    "\n",
    "fig = px.histogram(dfaa, x=\"AllocationLegalStatusCodeCV\")\n",
    "fig.update_layout(bargap=0.2,\n",
    "                  title=\"Histogram of AllocationLegalStatusCodeCV Entries in waterallocations.csv\",\n",
    "                  xaxis_title=\"AllocationLegalStatusCodeCV Value\",\n",
    "                  yaxis_title=\"# of entries\",\n",
    "                  #legend_title=\"Legend Title\",\n",
    "                    font=dict(\n",
    "                        family=\"Arial Bold\",\n",
    "                        size=12,\n",
    "                        color=\"Black\")\n",
    "                 )\n",
    "fig.show()\n",
    "fig.write_image('figures/AllocationLegalStatusCodeCV.png', engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34259ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- AllocationFlow_CFS: Boxplot distribution of WaDE values ----\n",
    "\n",
    "try: \n",
    "    trace1 = go.Violin(x=dfaa['AllocationFlow_CFS'], points='outliers', name='Violin Plot')\n",
    "    trace2 = go.Histogram(x=dfaa['AllocationFlow_CFS'], name='Historgram')\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "    fig.add_trace(trace1, row=1, col=1)\n",
    "    fig.add_trace(trace2, row=2, col=1)\n",
    "\n",
    "    fig.update_layout(showlegend=False, bargap=0.2, title=\"AllocationFlow_CFS Distribution in waterallocations.csv\", font=dict(family=\"Arial Bold\", size=12,color=\"Black\"))\n",
    "    fig.update_xaxes(title_text=\"AllocationFlow_CFS Value\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"AllocationFlow_CFS Value\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Num. of Records\", row=2, col=1)\n",
    "    fig.show()\n",
    "    fig.write_image('figures/AllocationFlow_CFS.png', engine=\"kaleido\")\n",
    "\n",
    "except: print('Could not plot AllocationFlow_CFS value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09608e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- AllocationVolume_AF: Boxplot distribution of WaDE values ----\n",
    "\n",
    "try:\n",
    "    trace1 = go.Violin(x=dfaa['AllocationVolume_AF'], points='outliers', name='Violin Plot')\n",
    "    trace2 = go.Histogram(x=dfaa['AllocationVolume_AF'], name='Historgram')\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "    fig.add_trace(trace1, row=1, col=1)\n",
    "    fig.add_trace(trace2, row=2, col=1)\n",
    "\n",
    "    fig.update_layout(showlegend=False, bargap=0.2, title=\"AllocationVolume_AF Distribution in waterallocations.csv\", font=dict(family=\"Arial Bold\", size=12,color=\"Black\"))\n",
    "    fig.update_xaxes(title_text=\"AllocationVolume_AF Value\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"AllocationVolume_AF Value\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Num. of Records\", row=2, col=1)\n",
    "    fig.show()\n",
    "    fig.write_image('figures/AllocationVolume_AF.png', engine=\"kaleido\")\n",
    "\n",
    "except: print('Could not plot AllocationVolume_AF value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aef0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Map of Points sites ----\n",
    "\n",
    "dfstemp = Sites.copy()\n",
    "dfstemp = dfstemp[dfstemp['PODorPOUSite'] == 'POD'].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "    ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "    gdfstemp = gpd.GeoDataFrame(dfstemp, geometry=gpd.points_from_xy(dfstemp.Longitude.astype(float), dfstemp.Latitude.astype(float)), crs=\"EPSG:4326\")\n",
    "    gplt.pointplot(gdfstemp, hue='PODorPOUSite', legend=True, legend_var='hue', ax=ax)\n",
    "    mplt.savefig(format=\"png\", fname='figures/PointMap.png') \n",
    "except:\n",
    "    print('No point data to plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59152af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Map of Polygons ----\n",
    "\n",
    "dfstemp = Sites.copy()\n",
    "dfstemp = dfstemp[dfstemp['PODorPOUSite'] == 'POU'].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa')) # use for background map in subplot\n",
    "    ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator()) # set subplot\n",
    "\n",
    "    dfstemp['Geometry'] = gpd.GeoSeries.from_wkt(dfstemp['SiteGeometry'], crs=\"EPSG:4326\")\n",
    "    gdfstemp = gpd.GeoDataFrame(dfstemp, geometry=dfstemp['Geometry'], crs=\"EPSG:4326\") # covert to geodataframe\n",
    "    gplt.polyplot(gdfstemp, ax=ax)\n",
    "    mplt.savefig(format=\"png\", fname='figures/PolyMap.png')\n",
    "except:\n",
    "    print('No geometry data to plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6612a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
